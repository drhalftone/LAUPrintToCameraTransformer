# Pix2Pix Training Configuration for Print-to-Camera Transformation

# Data settings
data:
  data_dir: "./data"
  original_subdir: "original"
  captured_subdir: "captured"
  image_size: 512
  val_split: 0.1

# Model settings
model:
  features: 64          # Base feature channels (64 -> 128 -> 256 -> 512 -> 1024)
  use_gan: true         # Use PatchGAN discriminator
  use_perceptual: true  # Use VGG perceptual loss

# Training settings
training:
  output_dir: "./outputs_pix2pix"
  batch_size: 4         # Can use larger batch with simpler model
  learning_rate: 2.0e-4 # Standard pix2pix LR
  max_steps: 10000      # More steps for better convergence
  save_steps: 2000
  log_steps: 100
  mixed_precision: "fp16"
  num_workers: 4
  seed: 42

  # Loss weights
  lambda_l1: 100.0          # L1 reconstruction weight (high = sharper)
  lambda_perceptual: 10.0   # Perceptual loss weight
  lambda_gan: 1.0           # Adversarial loss weight
