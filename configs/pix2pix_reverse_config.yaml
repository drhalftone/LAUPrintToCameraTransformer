# Pix2Pix Reverse Training Configuration
# Trains: Captured/Printed -> Original (restoration/correction)

# Data settings (REVERSED: captured is input, original is target)
data:
  data_dir: "./data"
  original_subdir: "captured"    # Input: captured/printed images
  captured_subdir: "original"    # Target: original digital images
  image_size: 512
  val_split: 0.1

# Model settings
model:
  features: 64          # Base feature channels (64 -> 128 -> 256 -> 512 -> 1024)
  use_gan: true         # Use PatchGAN discriminator
  use_perceptual: true  # Use VGG perceptual loss

# Training settings
training:
  output_dir: "./outputs_pix2pix_reverse"
  batch_size: 4
  learning_rate: 2.0e-4
  max_steps: 10000
  save_steps: 2000
  log_steps: 100
  mixed_precision: "fp16"
  num_workers: 4
  seed: 42

  # Loss weights
  lambda_l1: 100.0
  lambda_perceptual: 10.0
  lambda_gan: 1.0
